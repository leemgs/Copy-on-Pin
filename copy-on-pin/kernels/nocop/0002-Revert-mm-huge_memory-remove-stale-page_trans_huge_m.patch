From 1ce9abb223946de95fa74b1e14227282c02aec2b Mon Sep 17 00:00:00 2001
From: David Hildenbrand <hildenbr@in.tum.de>
Date: Tue, 4 Oct 2022 13:11:28 -0400
Subject: [PATCH 02/11] Revert "mm/huge_memory: remove stale
 page_trans_huge_mapcount()"

This reverts commit 55c62fa7c53368a9011cd1276c001a1469078c6a.

Signed-off-by: David Hildenbrand <hildenbr@in.tum.de>
---
 include/linux/mm.h |  5 +++++
 mm/huge_memory.c   | 48 ++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 53 insertions(+)

diff --git a/include/linux/mm.h b/include/linux/mm.h
index 9f44254af8ce..8aa3069d8bfa 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -834,11 +834,16 @@ static inline int total_mapcount(struct page *page)
 	return folio_mapcount(page_folio(page));
 }
 
+int page_trans_huge_mapcount(struct page *page);
 #else
 static inline int total_mapcount(struct page *page)
 {
 	return page_mapcount(page);
 }
+static inline int page_trans_huge_mapcount(struct page *page)
+{
+	return page_mapcount(page);
+}
 #endif
 
 static inline struct page *virt_to_head_page(const void *x)
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index 7bfcb2d64d2e..094b5dc7a2a1 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -2483,6 +2483,54 @@ static void __split_huge_page(struct page *page, struct list_head *list,
 	}
 }
 
+/*
+ * This calculates accurately how many mappings a transparent hugepage
+ * has (unlike page_mapcount() which isn't fully accurate). This full
+ * accuracy is primarily needed to know if copy-on-write faults can
+ * reuse the page and change the mapping to read-write instead of
+ * copying them. At the same time this returns the total_mapcount too.
+ *
+ * The function returns the highest mapcount any one of the subpages
+ * has. If the return value is one, even if different processes are
+ * mapping different subpages of the transparent hugepage, they can
+ * all reuse it, because each process is reusing a different subpage.
+ *
+ * The total_mapcount is instead counting all virtual mappings of the
+ * subpages. If the total_mapcount is equal to "one", it tells the
+ * caller all mappings belong to the same "mm" and in turn the
+ * anon_vma of the transparent hugepage can become the vma->anon_vma
+ * local one as no other process may be mapping any of the subpages.
+ *
+ * It would be more accurate to replace page_mapcount() with
+ * page_trans_huge_mapcount(), however we only use
+ * page_trans_huge_mapcount() in the copy-on-write faults where we
+ * need full accuracy to avoid breaking page pinning, because
+ * page_trans_huge_mapcount() is slower than page_mapcount().
+ */
+int page_trans_huge_mapcount(struct page *page)
+{
+	int i, ret;
+
+	/* hugetlbfs shouldn't call it */
+	VM_BUG_ON_PAGE(PageHuge(page), page);
+
+	if (likely(!PageTransCompound(page)))
+		return atomic_read(&page->_mapcount) + 1;
+
+	page = compound_head(page);
+
+	ret = 0;
+	for (i = 0; i < thp_nr_pages(page); i++) {
+		int mapcount = atomic_read(&page[i]._mapcount) + 1;
+		ret = max(ret, mapcount);
+	}
+
+	if (PageDoubleMap(page))
+		ret -= 1;
+
+	return ret + compound_mapcount(page);
+}
+
 /* Racy check whether the huge page can be split */
 bool can_split_folio(struct folio *folio, int *pextra_pins)
 {
-- 
2.37.3

